{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "from mlagents.trainers.ppo.models import PPOModel\n",
    "from mlagents.trainers.ppo.trainer import PPOTrainer, discount_rewards\n",
    "from mlagents.trainers.ppo.policy import PPOPolicy\n",
    "from mlagents.trainers.rl_trainer import AllRewardsOutput\n",
    "from mlagents.trainers.components.reward_signals import RewardSignalResult\n",
    "from mlagents.envs.brain import BrainParameters, CameraResolution\n",
    "from mlagents.envs.environment import UnityEnvironment\n",
    "from mlagents.envs.mock_communicator import MockCommunicator\n",
    "from mlagents.trainers.tests import mock_brain as mb\n",
    "from mlagents.trainers.tests.mock_brain import make_brain_parameters\n",
    "from mlagents.trainers.custom_layer_specs import CustomConvLayerSpecs\n",
    "\n",
    "from mlagents.trainers.learn import CommandLineOptions, parse_command_line, create_sampler_manager, try_create_meta_curriculum, prepare_for_docker_run, create_environment_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_name = \"../../../../../../ml-agents-master/envs/first_try_conv/Unity Environment\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_config():\n",
    "    return yaml.safe_load(\n",
    "        \"\"\"\n",
    "        trainer: ppo\n",
    "        batch_size: 32\n",
    "        beta: 5.0e-3\n",
    "        buffer_size: 512\n",
    "        epsilon: 0.2\n",
    "        hidden_units: 128\n",
    "        lambd: 0.95\n",
    "        learning_rate: 3.0e-4\n",
    "        vis_encode_type: custom\n",
    "        max_steps: 5.0e4\n",
    "        normalize: true\n",
    "        num_epoch: 5\n",
    "        num_layers: 2\n",
    "        time_horizon: 64\n",
    "        sequence_length: 64\n",
    "        summary_freq: 1000\n",
    "        use_recurrent: false\n",
    "        memory_size: 8\n",
    "        curiosity_strength: 0.0\n",
    "        curiosity_enc_size: 1\n",
    "        summary_path: test\n",
    "        model_path: test\n",
    "        reward_signals:\n",
    "          extrinsic:\n",
    "            strength: 1.0\n",
    "            gamma: 0.99\n",
    "        \"\"\"\n",
    "    )\n",
    "#         vis_encode_type: custom / simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonoBleedingEdge\n",
      "Unity Environment.exe\n",
      "Unity Environment_Data\n",
      "UnityCrashHandler64.exe\n",
      "UnityPlayer.dll\n",
      "WinPixEventRuntime.dll\n"
     ]
    }
   ],
   "source": [
    "# Check if it is the correct folder\n",
    "import os\n",
    "environment_dir = \"/\".join(env_name.split(\"/\")[:-1])\n",
    "for folder in os.listdir(environment_dir):\n",
    "    print(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlagents.envs:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Training Brains : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(env_name)\n",
    "brain_infos = env.reset(train_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_brain = env.external_brain_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_info = brain_infos[default_brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_parameters = dummy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainer': 'ppo',\n",
       " 'batch_size': 32,\n",
       " 'beta': 0.005,\n",
       " 'buffer_size': 512,\n",
       " 'epsilon': 0.2,\n",
       " 'hidden_units': 128,\n",
       " 'lambd': 0.95,\n",
       " 'learning_rate': 0.0003,\n",
       " 'vis_encode_type': 'custom',\n",
       " 'max_steps': '5.0e4',\n",
       " 'normalize': True,\n",
       " 'num_epoch': 5,\n",
       " 'num_layers': 2,\n",
       " 'time_horizon': 64,\n",
       " 'sequence_length': 64,\n",
       " 'summary_freq': 1000,\n",
       " 'use_recurrent': False,\n",
       " 'memory_size': 8,\n",
       " 'curiosity_strength': 0.0,\n",
       " 'curiosity_enc_size': 1,\n",
       " 'summary_path': 'test',\n",
       " 'model_path': 'test',\n",
       " 'reward_signals': {'extrinsic': {'strength': 1.0, 'gamma': 0.99}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_parameters[\"layers_specs\"] = [\n",
    "    {\n",
    "        \"type\": \"conv2D\",\n",
    "        \"filters\": 32,\n",
    "        \"activation\": \"relu\",\n",
    "        \"use_bias\": True,\n",
    "        \"maxPool\": False,\n",
    "        \"kernel_shape\": (8,8),\n",
    "        \"strides\": (4,4),\n",
    "        \"kernel_initializer\": \"glorot_uniform\",\n",
    "        \"bias_initializer\": \"zeros\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"conv2D\",\n",
    "        \"filters\": 32,\n",
    "        \"activation\": \"relu\",\n",
    "        \"use_bias\": True,\n",
    "        \"maxPool\": False,\n",
    "        \"kernel_shape\": (4,4),\n",
    "        \"strides\": (2,2),\n",
    "        \"kernel_initializer\": \"glorot_uniform\",\n",
    "        \"bias_initializer\": \"zeros\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = trainer_parameters[\"layers_specs\"][0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = CustomConvLayerSpecs(**temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters': 32,\n",
       " 'kernel_shape': (8, 8),\n",
       " 'strides': (4, 4),\n",
       " 'activation': 'relu',\n",
       " 'kernel_initializer': 'glorot_uniform',\n",
       " 'bias_initializer': 'zeros',\n",
       " 'use_bias': True,\n",
       " 'maxPool': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RollerBallVisualBrain']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.external_brain_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer.py:59: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer.py:59: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:64: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:64: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:71: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:71: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:40: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:40: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:99: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:99: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:102: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:102: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:182: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:182: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--check\n",
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:318: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:318: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlagents.trainers.custom_layer_specs.CustomConvLayerSpecs object at 0x00000134A7781A88>\n",
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:336: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:336: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlagents.trainers.custom_layer_specs.CustomConvLayerSpecs object at 0x00000134A7781F08>\n",
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:248: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:248: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--check\n",
      "<mlagents.trainers.custom_layer_specs.CustomConvLayerSpecs object at 0x00000134A7781A88>\n",
      "<mlagents.trainers.custom_layer_specs.CustomConvLayerSpecs object at 0x00000134A7781F08>\n",
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:117: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:117: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:142: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:142: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:115: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:115: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:350: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:350: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:382: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\ppo\\models.py:382: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:91: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:91: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:92: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:92: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera_resolution = CameraResolution(84,84,3)\n",
    "brain_params = BrainParameters(\n",
    "    \"test_brain\",        # brain_name\n",
    "    0,                   # vector_observation_space_size\n",
    "    0,                   # num_stacked_vector_observations\n",
    "    [camera_resolution], # camera_resolutions\n",
    "    [4],                 # vector_action_space_size\n",
    "    [],                  # vector_action_descriptions\n",
    "    1                    # vector_action_space_type\n",
    ")\n",
    "trainer = PPOTrainer(brain_params, 0, trainer_parameters, True, False, 0, \"0\", False)\n",
    "policy = trainer.policy\n",
    "model = policy.model\n",
    "# policy = PPOPolicy(0, env.brains[env.external_brain_names[0]], trainer_parameters, False, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlagents.envs.brain.BrainInfo object at 0x00000134A76F4748>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "brain_info = brain_infos[default_brain]\n",
    "print(brain_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent observations look like:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Examine the observation space for the default brain\n",
    "for observation in brain_info.visual_observations:\n",
    "    print(\"Agent observations look like:\")\n",
    "    observation = np.array(observation)\n",
    "    if observation.shape[3] == 3:\n",
    "        plt.imshow(observation[0,:,:,:])\n",
    "    else:\n",
    "        plt.imshow(observation[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.policy.evaluate(brain_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_out = policy.get_value_estimates(brain_info, 0, done=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_out = policy.evaluate(brain_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_info.visual_observations[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': array([[ 0.4699039 , -0.0422685 , -0.28713787,  0.24907106]],\n",
       "       dtype=float32),\n",
       " 'log_probs': array([[-1.904729 , -0.9266766, -1.288302 , -1.1981091]], dtype=float32),\n",
       " 'value_heads': {'extrinsic': array([[-0.0326346]], dtype=float32)},\n",
       " 'value': array([[-0.0326346]], dtype=float32),\n",
       " 'entropy': array([1.4189385], dtype=float32),\n",
       " 'learning_rate': 0.0003,\n",
       " 'pre_action': array([[ 1.4097116, -0.1268055, -0.8614136,  0.7472132]], dtype=float32),\n",
       " 'random_normal_epsilon': array([[ 1.40413   , -0.12440282, -0.85949221,  0.74722242]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action : [[ 0.4699039  -0.0422685  -0.28713787  0.24907106]]\n",
      "log_probs : [[-1.904729  -0.9266766 -1.288302  -1.1981091]]\n",
      "value_heads : {'extrinsic': array([[-0.0326346]], dtype=float32)}\n",
      "value : [[-0.0326346]]\n",
      "entropy : [1.4189385]\n",
      "learning_rate : 0.0003\n",
      "pre_action : [[ 1.4097116 -0.1268055 -0.8614136  0.7472132]]\n",
      "random_normal_epsilon : [[ 1.40413    -0.12440282 -0.85949221  0.74722242]]\n"
     ]
    }
   ],
   "source": [
    "for key, val in run_out.items():\n",
    "    print(key, \":\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'action:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'vector_observation:0' shape=(?, 0) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'visual_observation_0:0' shape=(?, 84, 84, 3) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_6:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_dict = {\n",
    "#     policy.model.batch_size: 1,\n",
    "#     policy.model.sequence_length: 1,\n",
    "# }\n",
    "# for i in range(len(brain_info.visual_observations)):\n",
    "#     feed_dict[policy.model.visual_in[i]] = [\n",
    "#         brain_info.visual_observations[i][0]\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlagents.envs:Environment shut down with return code 0 (CTRL_C_EVENT).\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer_config = dummy_config()\n",
    "trainer_config[\"layers_specs\"] = [\n",
    "    {\n",
    "        \"type\": \"conv2D\",\n",
    "        \"filters\": 32,\n",
    "        \"activation\": \"relu\",\n",
    "        \"use_bias\": True,\n",
    "        \"maxPool\": False,\n",
    "        \"kernel_shape\": (8,8),\n",
    "        \"strides\": (4,4),\n",
    "        \"kernel_initializer\": \"glorot_uniform\",\n",
    "        \"bias_initializer\": \"zeros\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"conv2D\",\n",
    "        \"filters\": 32,\n",
    "        \"activation\": \"relu\",\n",
    "        \"use_bias\": True,\n",
    "        \"maxPool\": False,\n",
    "        \"kernel_shape\": (4,4),\n",
    "        \"strides\": (2,2),\n",
    "        \"kernel_initializer\": \"glorot_uniform\",\n",
    "        \"bias_initializer\": \"zeros\",\n",
    "    }\n",
    "]\n",
    "trainer_config = {\n",
    "    \"default\": trainer_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultCommandLineOptionsDict = {\n",
    "    \"debug\":False,\n",
    "    \"num_runs\": 1,\n",
    "    \"seed\": -1,\n",
    "    \"env_path\": env_name,\n",
    "    \"run_id\": \"ppo_test\",\n",
    "    \"load_model\": False,\n",
    "    \"train_model\": True,\n",
    "    \"save_freq\": 50000,\n",
    "    \"keep_checkpoints\": 5,\n",
    "    \"base_port\": 5005,\n",
    "    \"num_envs\": 1,\n",
    "    \"curriculum_folder\": None,\n",
    "    \"lesson\": 0,\n",
    "    \"slow\": False,\n",
    "    \"no_graphics\": False,\n",
    "    \"multi_gpu\": False,  \n",
    "    \"trainer_config_path\": \"boeit niet meer\",\n",
    "    \"sampler_file_path\": None,\n",
    "    \"docker_target_name\": None,\n",
    "    \"env_args\": None,\n",
    "    \"cpu\": False,\n",
    "}\n",
    "defaultCommandLineOptions = CommandLineOptions(**defaultCommandLineOptionsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unity ML-Agents Toolkit\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, Callable, Optional, List, NamedTuple\n",
    "\n",
    "\n",
    "from mlagents.trainers.trainer_controller import TrainerController\n",
    "from mlagents.trainers.exception import TrainerError\n",
    "from mlagents.trainers.meta_curriculum import MetaCurriculum\n",
    "from mlagents.trainers.trainer_util import load_config, TrainerFactory\n",
    "from mlagents.envs.environment import UnityEnvironment\n",
    "from mlagents.envs.sampler_class import SamplerManager\n",
    "from mlagents.envs.exception import SamplerException\n",
    "from mlagents.envs.base_unity_environment import BaseUnityEnvironment\n",
    "from mlagents.envs.subprocess_env_manager import SubprocessEnvManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(sub_id: int, run_seed: int, options: CommandLineOptions, process_queue: Queue, trainer_config):\n",
    "    curriculum_folder = options.curriculum_folder\n",
    "    # Recognize and use docker volume if one is passed as an argument\n",
    "    if not options.docker_target_name:\n",
    "        model_path = \"./models/{run_id}-{sub_id}\".format(\n",
    "            run_id=options.run_id, sub_id=sub_id\n",
    "        )\n",
    "        summaries_dir = \"./summaries\"\n",
    "    else:\n",
    "        if curriculum_folder is not None:\n",
    "            curriculum_folder = \"/{docker_target_name}/{curriculum_folder}\".format(\n",
    "                docker_target_name=options.docker_target_name,\n",
    "                curriculum_folder=curriculum_folder,\n",
    "            )\n",
    "        model_path = \"/{docker_target_name}/models/{run_id}-{sub_id}\".format(\n",
    "            docker_target_name=options.docker_target_name,\n",
    "            run_id=options.run_id,\n",
    "            sub_id=sub_id,\n",
    "        )\n",
    "        summaries_dir = \"/{docker_target_name}/summaries\".format(\n",
    "            docker_target_name=options.docker_target_name\n",
    "        )\n",
    "    port = options.base_port + (sub_id * options.num_envs)\n",
    "    if options.env_path is None:\n",
    "        port = 5004  # This is the in Editor Training Port\n",
    "    env_factory = create_environment_factory(\n",
    "        options.env_path,\n",
    "        options.docker_target_name,\n",
    "        options.no_graphics,\n",
    "        run_seed,\n",
    "        port,\n",
    "        options.env_args,\n",
    "    )\n",
    "    env = SubprocessEnvManager(env_factory, options.num_envs)\n",
    "    maybe_meta_curriculum = try_create_meta_curriculum(\n",
    "        curriculum_folder, env, options.lesson\n",
    "    )\n",
    "    sampler_manager, resampling_interval = create_sampler_manager(\n",
    "        options.sampler_file_path, env.reset_parameters, run_seed\n",
    "    )\n",
    "    trainer_factory = TrainerFactory(\n",
    "        trainer_config,\n",
    "        summaries_dir,\n",
    "        options.run_id,\n",
    "        model_path,\n",
    "        options.keep_checkpoints,\n",
    "        options.train_model,\n",
    "        options.load_model,\n",
    "        run_seed,\n",
    "        maybe_meta_curriculum,\n",
    "        options.multi_gpu,\n",
    "    )\n",
    "    # Create controller and begin training.\n",
    "    tc = TrainerController(\n",
    "        trainer_factory,\n",
    "        model_path,\n",
    "        summaries_dir,\n",
    "        options.run_id + \"-\" + str(sub_id),\n",
    "        options.save_freq,\n",
    "        maybe_meta_curriculum,\n",
    "        options.train_model,\n",
    "        run_seed,\n",
    "        options.fast_simulation,\n",
    "        sampler_manager,\n",
    "        resampling_interval,\n",
    "    )\n",
    "    # Signal that environment has been launched.\n",
    "    process_queue.put(True)\n",
    "    # Begin training\n",
    "    tc.start_learning(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer_controller.py:194: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer_controller.py:194: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--check\n",
      "<mlagents.trainers.custom_layer_specs.CustomConvLayerSpecs object at 0x00000134DBA803C8>\n",
      "<mlagents.trainers.custom_layer_specs.CustomConvLayerSpecs object at 0x00000134DBA80888>\n",
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:501: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\models.py:501: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "INFO:mlagents.envs:Hyperparameters for the PPOTrainer of brain RollerBallVisualBrain: \n",
      "\ttrainer:\tppo\n",
      "\tbatch_size:\t32\n",
      "\tbeta:\t0.005\n",
      "\tbuffer_size:\t512\n",
      "\tepsilon:\t0.2\n",
      "\thidden_units:\t128\n",
      "\tlambd:\t0.95\n",
      "\tlearning_rate:\t0.0003\n",
      "\tvis_encode_type:\tcustom\n",
      "\tmax_steps:\t5.0e4\n",
      "\tnormalize:\tTrue\n",
      "\tnum_epoch:\t5\n",
      "\tnum_layers:\t2\n",
      "\ttime_horizon:\t64\n",
      "\tsequence_length:\t64\n",
      "\tsummary_freq:\t1000\n",
      "\tuse_recurrent:\tFalse\n",
      "\tmemory_size:\t8\n",
      "\tcuriosity_strength:\t0.0\n",
      "\tcuriosity_enc_size:\t1\n",
      "\tsummary_path:\t./summaries/ppo_test_RollerBallVisualBrain\n",
      "\tmodel_path:\t./models/ppo_test-0/RollerBallVisualBrain\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    strength:\t1.0\n",
      "\t    gamma:\t0.99\n",
      "\tlayers_specs:\t[{'type': 'conv2D', 'filters': 32, 'activation': 'relu', 'use_bias': True, 'maxPool': False, 'kernel_shape': (8, 8), 'strides': (4, 4), 'kernel_initializer': 'glorot_uniform', 'bias_initializer': 'zeros'}, {'type': 'conv2D', 'filters': 32, 'activation': 'relu', 'use_bias': True, 'maxPool': False, 'kernel_shape': (4, 4), 'strides': (2, 2), 'kernel_initializer': 'glorot_uniform', 'bias_initializer': 'zeros'}]\n",
      "\tkeep_checkpoints:\t5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer.py:223: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer.py:223: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
      "\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 1000. Time Elapsed: 9.948 s Mean Reward: -0.600. Std of Reward: 0.800. Training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer.py:204: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\trainer.py:204: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 2000. Time Elapsed: 19.046 s Mean Reward: -0.660. Std of Reward: 0.751. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 3000. Time Elapsed: 27.580 s Mean Reward: -0.774. Std of Reward: 0.634. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 4000. Time Elapsed: 36.074 s Mean Reward: -0.804. Std of Reward: 0.595. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 5000. Time Elapsed: 44.493 s Mean Reward: -0.614. Std of Reward: 0.789. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 6000. Time Elapsed: 52.276 s Mean Reward: -0.538. Std of Reward: 0.843. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 7000. Time Elapsed: 60.727 s Mean Reward: -0.640. Std of Reward: 0.768. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 8000. Time Elapsed: 69.097 s Mean Reward: -0.542. Std of Reward: 0.841. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 9000. Time Elapsed: 77.569 s Mean Reward: -0.625. Std of Reward: 0.781. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 10000. Time Elapsed: 85.395 s Mean Reward: -0.689. Std of Reward: 0.725. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 11000. Time Elapsed: 93.927 s Mean Reward: -0.745. Std of Reward: 0.667. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 12000. Time Elapsed: 102.477 s Mean Reward: -0.769. Std of Reward: 0.639. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 13000. Time Elapsed: 110.972 s Mean Reward: -0.755. Std of Reward: 0.656. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 14000. Time Elapsed: 119.424 s Mean Reward: -0.615. Std of Reward: 0.788. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 15000. Time Elapsed: 127.436 s Mean Reward: -0.649. Std of Reward: 0.761. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 16000. Time Elapsed: 135.998 s Mean Reward: -0.679. Std of Reward: 0.735. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 17000. Time Elapsed: 144.469 s Mean Reward: -0.655. Std of Reward: 0.755. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 18000. Time Elapsed: 152.937 s Mean Reward: -0.600. Std of Reward: 0.800. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 19000. Time Elapsed: 161.377 s Mean Reward: -0.429. Std of Reward: 0.904. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 20000. Time Elapsed: 169.196 s Mean Reward: -0.636. Std of Reward: 0.771. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 21000. Time Elapsed: 177.650 s Mean Reward: -0.643. Std of Reward: 0.766. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 22000. Time Elapsed: 186.089 s Mean Reward: -0.469. Std of Reward: 0.883. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 23000. Time Elapsed: 194.555 s Mean Reward: -0.493. Std of Reward: 0.870. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 24000. Time Elapsed: 203.017 s Mean Reward: -0.516. Std of Reward: 0.857. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 25000. Time Elapsed: 210.809 s Mean Reward: -0.290. Std of Reward: 0.957. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 26000. Time Elapsed: 219.276 s Mean Reward: -0.361. Std of Reward: 0.933. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 27000. Time Elapsed: 227.720 s Mean Reward: -0.316. Std of Reward: 0.949. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 28000. Time Elapsed: 236.192 s Mean Reward: -0.169. Std of Reward: 0.986. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 29000. Time Elapsed: 244.047 s Mean Reward: -0.179. Std of Reward: 0.984. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 30000. Time Elapsed: 252.557 s Mean Reward: -0.152. Std of Reward: 0.988. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 31000. Time Elapsed: 261.075 s Mean Reward: -0.176. Std of Reward: 0.984. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 32000. Time Elapsed: 269.568 s Mean Reward: -0.159. Std of Reward: 0.987. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 33000. Time Elapsed: 277.382 s Mean Reward: -0.055. Std of Reward: 0.998. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 34000. Time Elapsed: 285.859 s Mean Reward: -0.087. Std of Reward: 0.996. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 35000. Time Elapsed: 294.296 s Mean Reward: -0.171. Std of Reward: 0.985. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 36000. Time Elapsed: 302.200 s Mean Reward: -0.031. Std of Reward: 1.000. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 37000. Time Elapsed: 310.706 s Mean Reward: -0.063. Std of Reward: 0.998. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 38000. Time Elapsed: 319.193 s Mean Reward: -0.082. Std of Reward: 0.997. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 39000. Time Elapsed: 327.613 s Mean Reward: -0.051. Std of Reward: 0.999. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 40000. Time Elapsed: 335.421 s Mean Reward: -0.068. Std of Reward: 0.998. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 41000. Time Elapsed: 343.892 s Mean Reward: 0.000. Std of Reward: 1.000. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 42000. Time Elapsed: 352.502 s Mean Reward: 0.064. Std of Reward: 0.998. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 43000. Time Elapsed: 361.198 s Mean Reward: -0.036. Std of Reward: 0.999. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 44000. Time Elapsed: 369.162 s Mean Reward: -0.012. Std of Reward: 1.000. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 45000. Time Elapsed: 377.644 s Mean Reward: -0.036. Std of Reward: 0.999. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 46000. Time Elapsed: 386.122 s Mean Reward: 0.083. Std of Reward: 0.997. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 47000. Time Elapsed: 394.568 s Mean Reward: 0.033. Std of Reward: 0.999. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 48000. Time Elapsed: 402.384 s Mean Reward: 0.041. Std of Reward: 0.999. Training.\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 49000. Time Elapsed: 410.807 s Mean Reward: 0.000. Std of Reward: 1.000. Training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:212: The name tf.train.write_graph is deprecated. Please use tf.io.write_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:212: The name tf.train.write_graph is deprecated. Please use tf.io.write_graph instead.\n",
      "\n",
      "INFO:mlagents.envs:Saved Model\n",
      "INFO:mlagents.trainers: ppo_test: RollerBallVisualBrain: Step: 50000. Time Elapsed: 420.366 s Mean Reward: -0.133. Std of Reward: 0.991. Training.\n",
      "INFO:mlagents.envs:Saved Model\n",
      "INFO:mlagents.trainers:List of nodes to export for brain :RollerBallVisualBrain\n",
      "INFO:mlagents.trainers:\tis_continuous_control\n",
      "INFO:mlagents.trainers:\tversion_number\n",
      "INFO:mlagents.trainers:\tmemory_size\n",
      "INFO:mlagents.trainers:\taction_output_shape\n",
      "INFO:mlagents.trainers:\taction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:225: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tf_policy.py:225: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rick\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 13 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 13 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 13 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 13 variables to const ops.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./models/ppo_test-0/RollerBallVisualBrain/frozen_graph_def.pb to ./models/ppo_test-0/RollerBallVisualBrain.nn\n",
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tensorflow_to_barracuda.py:1539: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rick\\documents\\github\\ml-agents\\ml-agents\\mlagents\\trainers\\tensorflow_to_barracuda.py:1539: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "INFO:mlagents.trainers:Exported ./models/ppo_test-0/RollerBallVisualBrain.nn file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBALS: 'is_continuous_control', 'version_number', 'memory_size', 'action_output_shape'\n",
      "IN: 'visual_observation_0': [-1, 84, 84, 3] => 'main_graph_0_encoder0/conv_0/BiasAdd'\n",
      "IN: 'action_masks': [-1, 1, 1, 4] => 'strided_slice_1'\n",
      "OUT: 'concat/concat', 'action_probs/action_probs', 'concat_3/concat', 'action'\n",
      "DONE: wrote ./models/ppo_test-0/RollerBallVisualBrain.nn file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_seed = np.random.randint(0, 10000)\n",
    "run_training(0, run_seed, defaultCommandLineOptions, Queue(), trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': {'trainer': 'ppo',\n",
       "  'batch_size': 32,\n",
       "  'beta': 0.005,\n",
       "  'buffer_size': 512,\n",
       "  'epsilon': 0.2,\n",
       "  'hidden_units': 128,\n",
       "  'lambd': 0.95,\n",
       "  'learning_rate': 0.0003,\n",
       "  'vis_encode_type': 'custom',\n",
       "  'max_steps': '5.0e4',\n",
       "  'normalize': True,\n",
       "  'num_epoch': 5,\n",
       "  'num_layers': 2,\n",
       "  'time_horizon': 64,\n",
       "  'sequence_length': 64,\n",
       "  'summary_freq': 1000,\n",
       "  'use_recurrent': False,\n",
       "  'memory_size': 8,\n",
       "  'curiosity_strength': 0.0,\n",
       "  'curiosity_enc_size': 1,\n",
       "  'summary_path': 'test',\n",
       "  'model_path': 'test',\n",
       "  'reward_signals': {'extrinsic': {'strength': 1.0, 'gamma': 0.99}},\n",
       "  'layers_specs': [{'type': 'conv2D',\n",
       "    'filters': 32,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'maxPool': False,\n",
       "    'kernel_shape': (8, 8),\n",
       "    'strides': (4, 4),\n",
       "    'kernel_initializer': 'glorot_uniform',\n",
       "    'bias_initializer': 'zeros'},\n",
       "   {'type': 'conv2D',\n",
       "    'filters': 32,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'maxPool': False,\n",
       "    'kernel_shape': (4, 4),\n",
       "    'strides': (2, 2),\n",
       "    'kernel_initializer': 'glorot_uniform',\n",
       "    'bias_initializer': 'zeros'}]}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
